{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will help you get started solving the given problem. In this challenge, we have to predict the attack type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data has 169307 rows and 43 columns\n",
      "The test data has 91166 rows and 42 columns\n"
     ]
    }
   ],
   "source": [
    "print('The train data has {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
    "print('The test data has {} rows and {} columns'.format(test.shape[0], test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.583957\n",
       "2    0.217676\n",
       "1    0.198367\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check target class\n",
    "train['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't any missing values. Let's jump to building models to get some baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "connection_id    0\n",
       "cont_1           0\n",
       "cont_2           0\n",
       "cont_3           0\n",
       "cont_4           0\n",
       "cont_5           0\n",
       "cont_6           0\n",
       "cont_7           0\n",
       "cont_8           0\n",
       "cont_9           0\n",
       "cont_10          0\n",
       "cont_11          0\n",
       "cont_12          0\n",
       "cont_13          0\n",
       "cont_14          0\n",
       "cont_15          0\n",
       "cont_16          0\n",
       "cont_17          0\n",
       "cont_18          0\n",
       "cat_1            0\n",
       "cat_2            0\n",
       "cat_3            0\n",
       "cat_4            0\n",
       "cat_5            0\n",
       "cat_6            0\n",
       "cat_7            0\n",
       "cat_8            0\n",
       "cat_9            0\n",
       "cat_10           0\n",
       "cat_11           0\n",
       "cat_12           0\n",
       "cat_13           0\n",
       "cat_14           0\n",
       "cat_15           0\n",
       "cat_16           0\n",
       "cat_17           0\n",
       "cat_18           0\n",
       "cat_19           0\n",
       "cat_20           0\n",
       "cat_21           0\n",
       "cat_22           0\n",
       "cat_23           0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check missing values\n",
    "train.isnull().sum(axis=0) ## there are no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 0 (Majority Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## lets make a submission with all 0s\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['target'] = 0\n",
    "sub.to_csv('sub0.csv', index=False) ## 0.58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_names = [x for x in train.columns if x not in ['connection_id','target']]\n",
    "target = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, train_size = 0.7, stratify = target, random_state = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function for multi-accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "def multAcc(pred, dtrain):\n",
    "    label = dtrain.get_label()\n",
    "    acc = accuracy_score(label, pred)\n",
    "    return 'maccuracy', acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default parameters\n",
    "params = {'objective':'multi:softmax',\n",
    "          'num_class':3,\n",
    "          # 'eval_metric':'merror'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=X_train[feature_names], label=y_train)\n",
    "dvalid = xgb.DMatrix(data=X_valid[feature_names], label=y_valid)\n",
    "dtest = xgb.DMatrix(data=test[feature_names])\n",
    "watchlist = [(dtrain, 'train'),(dvalid, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-maccuracy:0.992024\teval-maccuracy:0.366262\n",
      "Multiple eval metrics have been passed: 'eval-maccuracy' will be used for early stopping.\n",
      "\n",
      "Will train until eval-maccuracy hasn't improved in 40 rounds.\n",
      "[20]\ttrain-maccuracy:0.995054\teval-maccuracy:0.36699\n",
      "[40]\ttrain-maccuracy:0.995199\teval-maccuracy:0.36699\n",
      "[60]\ttrain-maccuracy:0.995319\teval-maccuracy:0.36699\n",
      "[80]\ttrain-maccuracy:0.995384\teval-maccuracy:0.367051\n",
      "Stopping. Best iteration:\n",
      "[44]\ttrain-maccuracy:0.995223\teval-maccuracy:0.367051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = xgb.train(params, dtrain, 1000, watchlist, maximize=True, verbose_eval=20, early_stopping_rounds=1000, feval=multAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf1.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## make submission\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['target'] = pred\n",
    "sub['target'] = sub['target'].astype(int)\n",
    "sub.to_csv('sub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set up model\n",
    "clf2 = GradientBoostingClassifier(n_estimators = 130,learning_rate=0.083,max_depth=4, min_samples_split=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.083, loss='deviance', max_depth=4,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=6,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=130,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model\n",
    "clf2.fit(train[feature_names], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## make prediction\n",
    "pred2 = clf2.predict(test[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make submission\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['target'] = pred2\n",
    "sub['target'] = sub['target'].astype(int)\n",
    "sub.to_csv('sub2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf3 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(train[feature_names], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred3 = clf3.predict(test[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## make submission\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['target'] = pred3\n",
    "sub['target'] = sub['target'].astype(int)\n",
    "sub.to_csv('sub3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
